- 2020.12.05
>loss的计算应该放在网络里面合适，对于一些不同的任务,loss的计算方式及参数很难统一起来
一些中间输出也应该放在具体的网络里面，保证框架的统一，框架解耦的目的是能使网络插件化，对于网络内部的操作，通用性高就再解耦

- 2021.01.05
> mmdet方式的look和runner架构迁移遇到问题，需要细读mmcv相关源码，理解
>
>目前还是先实现一版registry的
>
>还有一个疑惑，像optimizer,loss,postprecess应该放到网络里面吗?应该包含进去，不同算法后处理参数不一样
>
>
- 2021.01.09
>复现时，先用测试集过拟合网络，同时验证复现的正确
>
>关于复现网络，和原作者查一两个点的问题怎么排查
>

- 2021.01.11
>基于分割的检测，map图的创建方式很多，但是基本都是大同小异，怎么去解耦



- 2021.01.27
>记录一次由dataloader的shffle=False，导致的精度一直在很低的范围内波动，由于引入dist分布式训练，shuffle因为False，训练集每个epoch不打乱，导致问题
>



# to do list
1.dist的dataloader shuffle问题-->已经修复
2.网络输出多个head的，应该concat起来，后处理按照相应通道选取，这样子对性能会有好处

